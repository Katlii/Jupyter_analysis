{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f68d31a",
   "metadata": {},
   "source": [
    "# Research/summary of metrics for calculating distance between two DISCRETE and INDEPENDENT arrays.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3476f88",
   "metadata": {},
   "source": [
    "The concept of clustering\n",
    "\n",
    "Clustering (or cluster analysis) is the task of dividing a set of objects into groups, called clusters. Each group must have \"similar\" objects within it, and objects in different groups must be as different as possible. \n",
    "\n",
    "The application of cluster analysis in general is reduced to the following steps:\n",
    "1) Selecting a sample of objects for clustering.\n",
    "2) Determination of the set of variables by which the objects in the sample will be evaluated. If necessary, normalize the values of the variables.\n",
    "3) Calculating the values of the measure of similarity between objects.\n",
    "4) Using the cluster analysis method to create groups of similar objects (clusters).\n",
    "5) Presenting the results of the analysis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6262f124",
   "metadata": {},
   "source": [
    "# Measures of distance\n",
    "\n",
    "So, how do we determine the \"similarity\" of objects? \n",
    "\n",
    "To begin with, we need to create a vector of characteristics for each object.\n",
    "Once we have defined a vector of characteristics, we can perform normalization, so that all components give the same contribution in calculating \"distance\". In the normalisation process, all values are reduced to a certain range, e.g. [1,0,0,1]\n",
    "\n",
    "Finally, for each pair of objects the \"distance\" between them - the measure of similarity - is measured. There are many metrics, here are just the main ones:\n",
    "\n",
    "1) Euclidean distance\n",
    "The most widely used distance function. Represents the geometric distance in multidimensional space\n",
    "2) City block distance (Manhattan distance)\n",
    "Distance is also known as city block distance, Manhattan distance, taxi distance, rectangular city metric - it measures distance in blocks rather than by the shortest straight line.\n",
    "3) Chebyshev distance (chessboard metric)\n",
    "The difference between Manhattan distance and the Chebyshev distance is that moving one square diagonally in the first case counts two moves (e.g. up and left), while in the second case only one move counts.\n",
    "Also, both of these distances are different from the Euclidean distance in so far as the Euclidean distance has a diagonal move calculated by Pythagoras' theorem.\n",
    "4) Canberra distance\n",
    "The metric is very sensitive to small changes in coordinates and opposite to changes in data if they are large.\n",
    "5) Cosine similarity.\n",
    "Is a measure of similarity between two vectors of an inner product space that measures the cosine of the angle between them. It is often used in information retrieval and text mining applications to measure the similarity between documents or word vectors. Cosine similarity is frequently used in recommendation systems, natural language processing, and machine learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099e683a",
   "metadata": {},
   "source": [
    "There are also many specialized clustering algorithms that are tailored to specific applications, such as k-means clustering for numerical data and density-based clustering for dimensional data.\n",
    "\n",
    "K-means  clustering is a unsupervised learning algorithm that splits the data into k clusters, where k is specified in advance. The algorithm refers each data point to the nearest cluster by calculating the distance between the point and the centre of the cluster. The centres are re-calculated after each assignment, and the process is repeated until the clusters no longer change. K-means clustering is commonly used for data analysis and cluster detection.\n",
    "\n",
    "Density clustering is an unsupervised learning algorithm that clusters data points based on their density or similarity to each other. This type of clustering is useful for identifying clusters of irregular shape. It also works well in noisy datasets that have bursts or areas of low density. Density-based clustering is often used for anomaly detection and dimensional clustering.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d03cd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
